{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "# 결과 저장 경로 생성\n",
    "output_dir = \"../results/models/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 로드\n",
    "df_cleaned = pd.read_csv(\"../data/processed/data_cleaned.csv\")\n",
    "\n",
    "# 데이터 분할 (특성(X)과 레이블(y) 분리)\n",
    "X = df_cleaned.drop(columns=['Label'])\n",
    "y = df_cleaned['Label']\n",
    "\n",
    "# 훈련/테스트 데이터 분할 (80% 훈련, 20% 테스트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 데이터 정규화 (평균 0, 표준편차 1로 변환)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - dense_3_loss: 0.7454 - dense_4_accuracy: 0.9671 - dense_4_loss: 0.0768 - loss: 0.4111 - val_dense_3_loss: 0.6881 - val_dense_4_accuracy: 0.9751 - val_dense_4_loss: 0.0543 - val_loss: 0.3712\n",
      "Epoch 2/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - dense_3_loss: 0.6948 - dense_4_accuracy: 0.9794 - dense_4_loss: 0.0468 - loss: 0.3708 - val_dense_3_loss: 0.6877 - val_dense_4_accuracy: 0.9793 - val_dense_4_loss: 0.0428 - val_loss: 0.3653\n",
      "Epoch 3/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - dense_3_loss: 0.6773 - dense_4_accuracy: 0.9816 - dense_4_loss: 0.0419 - loss: 0.3596 - val_dense_3_loss: 0.6875 - val_dense_4_accuracy: 0.9819 - val_dense_4_loss: 0.0363 - val_loss: 0.3619\n",
      "Epoch 4/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - dense_3_loss: 0.6958 - dense_4_accuracy: 0.9848 - dense_4_loss: 0.0356 - loss: 0.3657 - val_dense_3_loss: 0.6875 - val_dense_4_accuracy: 0.9913 - val_dense_4_loss: 0.0333 - val_loss: 0.3604\n",
      "Epoch 5/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - dense_3_loss: 0.6928 - dense_4_accuracy: 0.9895 - dense_4_loss: 0.0277 - loss: 0.3602 - val_dense_3_loss: 0.6873 - val_dense_4_accuracy: 0.9917 - val_dense_4_loss: 0.0227 - val_loss: 0.3550\n",
      "Epoch 6/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - dense_3_loss: 0.6797 - dense_4_accuracy: 0.9922 - dense_4_loss: 0.0215 - loss: 0.3506 - val_dense_3_loss: 0.6873 - val_dense_4_accuracy: 0.9896 - val_dense_4_loss: 0.0224 - val_loss: 0.3549\n",
      "Epoch 7/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - dense_3_loss: 0.6502 - dense_4_accuracy: 0.9929 - dense_4_loss: 0.0191 - loss: 0.3347 - val_dense_3_loss: 0.6874 - val_dense_4_accuracy: 0.9935 - val_dense_4_loss: 0.0169 - val_loss: 0.3522\n",
      "Epoch 8/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - dense_3_loss: 0.6750 - dense_4_accuracy: 0.9934 - dense_4_loss: 0.0179 - loss: 0.3464 - val_dense_3_loss: 0.6872 - val_dense_4_accuracy: 0.9946 - val_dense_4_loss: 0.0152 - val_loss: 0.3512\n",
      "Epoch 9/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - dense_3_loss: 0.7668 - dense_4_accuracy: 0.9936 - dense_4_loss: 0.0173 - loss: 0.3920 - val_dense_3_loss: 0.6873 - val_dense_4_accuracy: 0.9947 - val_dense_4_loss: 0.0151 - val_loss: 0.3512\n",
      "Epoch 10/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - dense_3_loss: 0.6913 - dense_4_accuracy: 0.9940 - dense_4_loss: 0.0167 - loss: 0.3540 - val_dense_3_loss: 0.6874 - val_dense_4_accuracy: 0.9954 - val_dense_4_loss: 0.0135 - val_loss: 0.3504\n",
      "Epoch 11/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - dense_3_loss: 0.7452 - dense_4_accuracy: 0.9944 - dense_4_loss: 0.0159 - loss: 0.3805 - val_dense_3_loss: 0.6871 - val_dense_4_accuracy: 0.9952 - val_dense_4_loss: 0.0135 - val_loss: 0.3503\n",
      "Epoch 12/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - dense_3_loss: 0.7404 - dense_4_accuracy: 0.9943 - dense_4_loss: 0.0158 - loss: 0.3781 - val_dense_3_loss: 0.6871 - val_dense_4_accuracy: 0.9955 - val_dense_4_loss: 0.0133 - val_loss: 0.3502\n",
      "Epoch 13/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - dense_3_loss: 0.6817 - dense_4_accuracy: 0.9946 - dense_4_loss: 0.0154 - loss: 0.3486 - val_dense_3_loss: 0.6872 - val_dense_4_accuracy: 0.9846 - val_dense_4_loss: 0.0710 - val_loss: 0.3791\n",
      "Epoch 14/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - dense_3_loss: 0.6367 - dense_4_accuracy: 0.9944 - dense_4_loss: 0.0162 - loss: 0.3264 - val_dense_3_loss: 0.6873 - val_dense_4_accuracy: 0.9951 - val_dense_4_loss: 0.0152 - val_loss: 0.3512\n",
      "Epoch 15/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - dense_3_loss: 0.7219 - dense_4_accuracy: 0.9948 - dense_4_loss: 0.0146 - loss: 0.3682 - val_dense_3_loss: 0.6871 - val_dense_4_accuracy: 0.9956 - val_dense_4_loss: 0.0125 - val_loss: 0.3498\n",
      "Epoch 16/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - dense_3_loss: 0.7320 - dense_4_accuracy: 0.9948 - dense_4_loss: 0.0146 - loss: 0.3733 - val_dense_3_loss: 0.6874 - val_dense_4_accuracy: 0.9915 - val_dense_4_loss: 0.0202 - val_loss: 0.3538\n",
      "Epoch 17/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 2ms/step - dense_3_loss: 0.6926 - dense_4_accuracy: 0.9948 - dense_4_loss: 0.0145 - loss: 0.3535 - val_dense_3_loss: 0.6877 - val_dense_4_accuracy: 0.9944 - val_dense_4_loss: 0.0162 - val_loss: 0.3520\n",
      "Epoch 18/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - dense_3_loss: 0.7351 - dense_4_accuracy: 0.9951 - dense_4_loss: 0.0137 - loss: 0.3744 - val_dense_3_loss: 0.6871 - val_dense_4_accuracy: 0.9926 - val_dense_4_loss: 0.0156 - val_loss: 0.3513\n",
      "Epoch 19/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - dense_3_loss: 0.7255 - dense_4_accuracy: 0.9950 - dense_4_loss: 0.0139 - loss: 0.3697 - val_dense_3_loss: 0.6871 - val_dense_4_accuracy: 0.9957 - val_dense_4_loss: 0.0133 - val_loss: 0.3502\n",
      "Epoch 20/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - dense_3_loss: 0.6710 - dense_4_accuracy: 0.9952 - dense_4_loss: 0.0136 - loss: 0.3423 - val_dense_3_loss: 0.6871 - val_dense_4_accuracy: 0.9923 - val_dense_4_loss: 0.0247 - val_loss: 0.3559\n",
      "Epoch 21/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - dense_3_loss: 0.6692 - dense_4_accuracy: 0.9950 - dense_4_loss: 0.0142 - loss: 0.3417 - val_dense_3_loss: 0.6870 - val_dense_4_accuracy: 0.9956 - val_dense_4_loss: 0.0124 - val_loss: 0.3497\n",
      "Epoch 22/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - dense_3_loss: 0.7363 - dense_4_accuracy: 0.9952 - dense_4_loss: 0.0136 - loss: 0.3749 - val_dense_3_loss: 0.6871 - val_dense_4_accuracy: 0.9954 - val_dense_4_loss: 0.0155 - val_loss: 0.3513\n",
      "Epoch 23/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - dense_3_loss: 0.6719 - dense_4_accuracy: 0.9953 - dense_4_loss: 0.0132 - loss: 0.3426 - val_dense_3_loss: 0.6870 - val_dense_4_accuracy: 0.9933 - val_dense_4_loss: 0.0141 - val_loss: 0.3506\n",
      "Epoch 24/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - dense_3_loss: 0.6622 - dense_4_accuracy: 0.9952 - dense_4_loss: 0.0137 - loss: 0.3379 - val_dense_3_loss: 0.6870 - val_dense_4_accuracy: 0.9957 - val_dense_4_loss: 0.0121 - val_loss: 0.3496\n",
      "Epoch 25/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - dense_3_loss: 0.6787 - dense_4_accuracy: 0.9953 - dense_4_loss: 0.0132 - loss: 0.3460 - val_dense_3_loss: 0.6869 - val_dense_4_accuracy: 0.9960 - val_dense_4_loss: 0.0114 - val_loss: 0.3492\n",
      "Epoch 26/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - dense_3_loss: 0.6671 - dense_4_accuracy: 0.9952 - dense_4_loss: 0.0140 - loss: 0.3406 - val_dense_3_loss: 0.6868 - val_dense_4_accuracy: 0.9933 - val_dense_4_loss: 0.0135 - val_loss: 0.3501\n",
      "Epoch 27/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - dense_3_loss: 0.6840 - dense_4_accuracy: 0.9954 - dense_4_loss: 0.0130 - loss: 0.3485 - val_dense_3_loss: 0.6869 - val_dense_4_accuracy: 0.9959 - val_dense_4_loss: 0.0120 - val_loss: 0.3495\n",
      "Epoch 28/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - dense_3_loss: 0.6617 - dense_4_accuracy: 0.9953 - dense_4_loss: 0.0132 - loss: 0.3375 - val_dense_3_loss: 0.6870 - val_dense_4_accuracy: 0.9957 - val_dense_4_loss: 0.0136 - val_loss: 0.3503\n",
      "Epoch 29/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - dense_3_loss: 0.6925 - dense_4_accuracy: 0.9954 - dense_4_loss: 0.0131 - loss: 0.3528 - val_dense_3_loss: 0.6869 - val_dense_4_accuracy: 0.9958 - val_dense_4_loss: 0.0119 - val_loss: 0.3494\n",
      "Epoch 30/50\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - dense_3_loss: 0.6910 - dense_4_accuracy: 0.9957 - dense_4_loss: 0.0128 - loss: 0.3519 - val_dense_3_loss: 0.6869 - val_dense_4_accuracy: 0.9959 - val_dense_4_loss: 0.0119 - val_loss: 0.3494\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder 커널 정의\n",
    "input_dim = X_train_scaled.shape[1]  # 입력 특성의 차원 (63)\n",
    "hidden_dim1 = 56  # 첫 번째 은닉층 차원\n",
    "encoding_dim = 49  # 차원 축소 목표 차원\n",
    "\n",
    "# 입력층 정의\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# 인코더 네트워크 (차원 축소)\n",
    "encoded = Dense(hidden_dim1, activation='relu')(input_layer)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# 디코더 네트워크 (복원 과정)\n",
    "decoded = Dense(hidden_dim1, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# 분류기 출력 (이진 분류기 추가)\n",
    "classification_output = Dense(1, activation='sigmoid')(encoded)\n",
    "\n",
    "# 1. Autoencoder + Binary Classifier 모델 정의\n",
    "autoencoder_classifier = Model(inputs=input_layer, outputs=[decoded, classification_output])\n",
    "autoencoder_classifier.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=['mean_squared_error', 'binary_crossentropy'],  # Autoencoder와 분류 손실\n",
    "    loss_weights=[0.5, 0.5],  # 손실 가중치\n",
    "    metrics={'dense_4': 'accuracy'}  # 분류기 정확도 추적\n",
    ")\n",
    "\n",
    "# EarlyStopping 콜백 설정 (모델이 더 이상 개선되지 않으면 학습 중단)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_dense_4_accuracy',  # 정확도 모니터링\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    mode='max'  # 정확도를 최대화하려면 'max'\n",
    ")\n",
    "\n",
    "# Autoencoder + Binary Classifier 모델 학습\n",
    "y_binary_train = (y_train != 0).astype(int)  # 이진 분류 (0이면 0, 아니면 1)\n",
    "y_binary_test = (y_test != 0).astype(int)\n",
    "\n",
    "autoencoder_classifier.fit(\n",
    "    X_train_scaled, [X_train_scaled, y_binary_train],  # 입력과 출력(원본 데이터와 분류 레이블)\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test_scaled, [X_test_scaled, y_binary_test]),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 모델 저장 (Keras 형식으로 저장)\n",
    "autoencoder_classifier.save(os.path.join(output_dir, \"autoencoder_classifier.keras\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70765/70765\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 746us/step\n",
      "\u001b[1m17692/17692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 675us/step\n",
      "Original shape: (2264474, 63)\n",
      "Reduced shape: (2264474, 49)\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder 차원 축소 (인코더만 추출)\n",
    "encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "\n",
    "# 차원 축소된 데이터 생성\n",
    "X_train_encoded = encoder.predict(X_train_scaled)\n",
    "X_test_encoded = encoder.predict(X_test_scaled)\n",
    "\n",
    "# 차원 축소된 데이터 차원 확인\n",
    "print(\"Original shape:\", X_train_scaled.shape)  # 원래 차원: (샘플 수, 63)\n",
    "print(\"Reduced shape:\", X_train_encoded.shape)  # 축소된 차원: (샘플 수, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Random Forest 이진 분류 모델 학습 (차원 축소된 데이터 사용)\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10, n_jobs=-1)\n",
    "rf.fit(X_train_encoded, y_binary_train)\n",
    "\n",
    "# Random Forest 모델 저장\n",
    "joblib.dump(rf, os.path.join(output_dir, \"autoencoder_random_forest.pkl\"))\n",
    "\n",
    "# 인코더 모델 저장 (HDF5 대신 Keras 형식으로 저장)\n",
    "encoder.save(os.path.join(output_dir, \"encoder.keras\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results/models/autoencoder_udbb.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. UDBB 설정 및 Random Forest 기반 모델 정의\n",
    "\n",
    "# UDBB 설정 및 Random Forest 기반 모델 정의\n",
    "base_estimator = RandomForestClassifier(\n",
    "    n_estimators=100, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "udbb_model = BalancedBaggingClassifier(\n",
    "    estimator=base_estimator,  # base_estimator -> estimator로 변경\n",
    "    sampling_strategy='auto',   # 자동으로 언더샘플링 비율 설정\n",
    "    replacement=False,          # 샘플링 시 중복 허용하지 않음\n",
    "    random_state=42,\n",
    "    n_estimators=100,           # 앙상블에 포함할 모델 개수\n",
    "    n_jobs=-1                   # 병렬 처리\n",
    ")\n",
    "\n",
    "# 모델 훈련 (차원 축소된 데이터를 사용)\n",
    "udbb_model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# 모델 저장\n",
    "joblib.dump(udbb_model, os.path.join(output_dir, \"autoencoder_udbb.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0502 - val_accuracy: 0.9960 - val_loss: 0.0139\n",
      "Epoch 2/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.9966 - val_loss: 0.0131\n",
      "Epoch 3/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0129 - val_accuracy: 0.9965 - val_loss: 0.0116\n",
      "Epoch 4/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0123 - val_accuracy: 0.9961 - val_loss: 0.0132\n",
      "Epoch 5/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0121 - val_accuracy: 0.9968 - val_loss: 0.0113\n",
      "Epoch 6/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0118 - val_accuracy: 0.9967 - val_loss: 0.0117\n",
      "Epoch 7/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 0.9966 - val_loss: 0.0117\n",
      "Epoch 8/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0115 - val_accuracy: 0.9967 - val_loss: 0.0113\n",
      "Epoch 9/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 0.9967 - val_loss: 0.0111\n",
      "Epoch 10/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0115 - val_accuracy: 0.9968 - val_loss: 0.0111\n",
      "Epoch 11/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0114 - val_accuracy: 0.9970 - val_loss: 0.0104\n",
      "Epoch 12/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0113 - val_accuracy: 0.9968 - val_loss: 0.0108\n",
      "Epoch 13/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 0.9968 - val_loss: 0.0114\n",
      "Epoch 14/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0110 - val_accuracy: 0.9971 - val_loss: 0.0109\n",
      "Epoch 15/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0107 - val_accuracy: 0.9971 - val_loss: 0.0108\n",
      "Epoch 16/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0105 - val_accuracy: 0.9973 - val_loss: 0.0108\n",
      "Epoch 17/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0107 - val_accuracy: 0.9973 - val_loss: 0.0103\n",
      "Epoch 18/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0107 - val_accuracy: 0.9972 - val_loss: 0.0102\n",
      "Epoch 19/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0104 - val_accuracy: 0.9974 - val_loss: 0.0107\n",
      "Epoch 20/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0105 - val_accuracy: 0.9971 - val_loss: 0.0107\n",
      "Epoch 21/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0104 - val_accuracy: 0.9972 - val_loss: 0.0108\n",
      "Epoch 22/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0102 - val_accuracy: 0.9973 - val_loss: 0.0105\n",
      "Epoch 23/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0104 - val_accuracy: 0.9969 - val_loss: 0.0126\n",
      "Epoch 24/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0106 - val_accuracy: 0.9974 - val_loss: 0.0107\n",
      "Epoch 25/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0106 - val_accuracy: 0.9972 - val_loss: 0.0107\n",
      "Epoch 26/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0109 - val_accuracy: 0.9968 - val_loss: 0.0112\n",
      "Epoch 27/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0105 - val_accuracy: 0.9973 - val_loss: 0.0112\n",
      "Epoch 28/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0107 - val_accuracy: 0.9965 - val_loss: 0.0154\n",
      "Epoch 29/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0106 - val_accuracy: 0.9972 - val_loss: 0.0106\n",
      "Epoch 30/30\n",
      "\u001b[1m35383/35383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0106 - val_accuracy: 0.9965 - val_loss: 0.0139\n"
     ]
    }
   ],
   "source": [
    "# 4. CNN 분류기 모델 구성 (Autoencoder로 차원 축소된 데이터 사용)\n",
    "cnn_classifier = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(encoding_dim, 1)),  # 인코딩된 데이터 차원 사용\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(15, activation='softmax')  # 다중 클래스 분류를 위한 소프트맥스 출력\n",
    "])\n",
    "\n",
    "# 모델 컴파일 (Adam optimizer와 sparse_categorical_crossentropy 손실 함수 사용)\n",
    "cnn_classifier.compile(\n",
    "    optimizer='adam',  # 최적화 기법\n",
    "    loss='sparse_categorical_crossentropy',  # 다중 클래스 분류 손실 함수\n",
    "    metrics=['accuracy']  # 평가 지표로 정확도 사용\n",
    ")\n",
    "\n",
    "# CNN 학습을 위해 입력 데이터 차원 변경 (CNN은 3D 입력을 요구)\n",
    "X_train_encoded_cnn = np.expand_dims(X_train_encoded, axis=-1)  # (샘플 수, 차원 수, 1)\n",
    "X_test_encoded_cnn = np.expand_dims(X_test_encoded, axis=-1)    # (샘플 수, 차원 수, 1)\n",
    "\n",
    "# CNN 모델 학습\n",
    "cnn_classifier.fit(\n",
    "    X_train_encoded_cnn, y_train,  # 타겟 데이터는 정수형(0~14)\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test_encoded_cnn, y_test)\n",
    ")\n",
    "\n",
    "# CNN 모델 저장\n",
    "cnn_classifier.save(os.path.join(output_dir, \"autoencoder_cnn.keras\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
